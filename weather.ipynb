{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"weather.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = dataset.iloc[:,-1]\n",
    "X = dataset.iloc[:,0:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "encode_x = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "wind_dir = X.iloc[:,5]\n",
    "categorical = encode_x.fit_transform(wind_dir)\n",
    "X.iloc[:,5] = categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib64/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['E', 'N', 'NE', 'NW', 'S', 'SE', 'SW', 'W'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode_x.inverse_transform([0,1,2,3,4,5,6,7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather = y\n",
    "cat = encode_x.fit_transform(weather)\n",
    "y = cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "OHE = OneHotEncoder(categorical_features=[5]) #5 is the position of data in datatset which is to be encoded\n",
    "X = OHE.fit_transform(X)\n",
    "X = X.toarray()      #converts X to array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0000e+00, 0.0000e+00, 0.0000e+00, ..., 5.0000e+01, 1.0197e+03,\n",
       "        7.0000e+00],\n",
       "       [1.0000e+00, 0.0000e+00, 0.0000e+00, ..., 5.0000e+01, 1.0124e+03,\n",
       "        5.0000e+00],\n",
       "       [0.0000e+00, 1.0000e+00, 0.0000e+00, ..., 4.5000e+01, 1.0095e+03,\n",
       "        8.0000e+00],\n",
       "       ...,\n",
       "       [1.0000e+00, 0.0000e+00, 0.0000e+00, ..., 6.0000e+01, 1.0123e+03,\n",
       "        1.0000e+00],\n",
       "       [1.0000e+00, 0.0000e+00, 0.0000e+00, ..., 7.7000e+01, 1.0157e+03,\n",
       "        7.0000e+00],\n",
       "       [1.0000e+00, 0.0000e+00, 0.0000e+00, ..., 7.4000e+01, 1.0185e+03,\n",
       "        8.0000e+00]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X[:,1:]              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1019.7, 1012.4, 1009.5, 1005.5, 1018.3, 1023.8, 1024.6, 1026.2,\n",
       "       1026.1, 1024.1, 1024.4, 1023.8, 1022. , 1017.3, 1018.2, 1017.9,\n",
       "       1014.4, 1016.4, 1017.1, 1018.5, 1012.4, 1010.7, 1014. , 1020.7,\n",
       "       1022.4, 1019.7, 1021. , 1019.2, 1019. , 1017.2, 1015. , 1013.9,\n",
       "       1007.9, 1007.3, 1015. , 1018.8, 1014.5, 1014.8, 1010.8, 1011.7,\n",
       "       1018. , 1021.1, 1021.9, 1018.1, 1012.6, 1010.1, 1017.6, 1020.6,\n",
       "       1018. , 1015.8, 1012.9,  996.5, 1009.5, 1012.8, 1020.4, 1023.2,\n",
       "       1017.3, 1016.8, 1017.1, 1017.4, 1019.2, 1015.8, 1012.6, 1016.8,\n",
       "       1016.2, 1011.8, 1006.6, 1012.3, 1015.7, 1018.5])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:,-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "bias_wt = np.ones((70,1)) #create and empty column of 70 rows with value 1.This is the weight of bias\n",
    "#2D array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_opt = np.append(arr = bias_wt, values=X, axis = 1) \n",
    "#add X in bias array..axis0=row(bydefault) axis1=xol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.755</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.680</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   10.18</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 22 May 2019</td> <th>  Prob (F-statistic):</th> <td>4.98e-11</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>23:46:02</td>     <th>  Log-Likelihood:    </th> <td> -51.297</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    70</td>      <th>  AIC:               </th> <td>   136.6</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    53</td>      <th>  BIC:               </th> <td>   174.8</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    16</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>   43.2509</td> <td>   21.351</td> <td>    2.026</td> <td> 0.048</td> <td>    0.426</td> <td>   86.075</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    0.0485</td> <td>    0.324</td> <td>    0.150</td> <td> 0.882</td> <td>   -0.602</td> <td>    0.699</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>   -0.7108</td> <td>    0.384</td> <td>   -1.849</td> <td> 0.070</td> <td>   -1.482</td> <td>    0.060</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>   -0.1500</td> <td>    0.270</td> <td>   -0.556</td> <td> 0.581</td> <td>   -0.691</td> <td>    0.392</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>   -0.1498</td> <td>    0.336</td> <td>   -0.446</td> <td> 0.657</td> <td>   -0.824</td> <td>    0.524</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td>   -0.0564</td> <td>    0.228</td> <td>   -0.247</td> <td> 0.806</td> <td>   -0.514</td> <td>    0.402</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6</th>    <td>   -0.4032</td> <td>    0.337</td> <td>   -1.198</td> <td> 0.236</td> <td>   -1.078</td> <td>    0.272</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7</th>    <td>   -0.5202</td> <td>    0.486</td> <td>   -1.070</td> <td> 0.289</td> <td>   -1.496</td> <td>    0.455</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8</th>    <td>   -0.0160</td> <td>    0.045</td> <td>   -0.357</td> <td> 0.723</td> <td>   -0.106</td> <td>    0.074</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9</th>    <td>   -0.0226</td> <td>    0.032</td> <td>   -0.714</td> <td> 0.478</td> <td>   -0.086</td> <td>    0.041</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x10</th>   <td>    0.0713</td> <td>    0.015</td> <td>    4.897</td> <td> 0.000</td> <td>    0.042</td> <td>    0.101</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x11</th>   <td>   -0.0820</td> <td>    0.038</td> <td>   -2.182</td> <td> 0.034</td> <td>   -0.157</td> <td>   -0.007</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x12</th>   <td>    0.0113</td> <td>    0.030</td> <td>    0.373</td> <td> 0.710</td> <td>   -0.050</td> <td>    0.072</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x13</th>   <td>   -0.0164</td> <td>    0.013</td> <td>   -1.288</td> <td> 0.203</td> <td>   -0.042</td> <td>    0.009</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x14</th>   <td>    0.0009</td> <td>    0.009</td> <td>    0.101</td> <td> 0.920</td> <td>   -0.016</td> <td>    0.018</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x15</th>   <td>   -0.0409</td> <td>    0.021</td> <td>   -1.979</td> <td> 0.053</td> <td>   -0.082</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x16</th>   <td>    0.1418</td> <td>    0.039</td> <td>    3.681</td> <td> 0.001</td> <td>    0.065</td> <td>    0.219</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 6.543</td> <th>  Durbin-Watson:     </th> <td>   1.992</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.038</td> <th>  Jarque-Bera (JB):  </th> <td>   6.192</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.518</td> <th>  Prob(JB):          </th> <td>  0.0452</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 4.025</td> <th>  Cond. No.          </th> <td>3.15e+05</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 3.15e+05. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.755\n",
       "Model:                            OLS   Adj. R-squared:                  0.680\n",
       "Method:                 Least Squares   F-statistic:                     10.18\n",
       "Date:                Wed, 22 May 2019   Prob (F-statistic):           4.98e-11\n",
       "Time:                        23:46:02   Log-Likelihood:                -51.297\n",
       "No. Observations:                  70   AIC:                             136.6\n",
       "Df Residuals:                      53   BIC:                             174.8\n",
       "Df Model:                          16                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const         43.2509     21.351      2.026      0.048       0.426      86.075\n",
       "x1             0.0485      0.324      0.150      0.882      -0.602       0.699\n",
       "x2            -0.7108      0.384     -1.849      0.070      -1.482       0.060\n",
       "x3            -0.1500      0.270     -0.556      0.581      -0.691       0.392\n",
       "x4            -0.1498      0.336     -0.446      0.657      -0.824       0.524\n",
       "x5            -0.0564      0.228     -0.247      0.806      -0.514       0.402\n",
       "x6            -0.4032      0.337     -1.198      0.236      -1.078       0.272\n",
       "x7            -0.5202      0.486     -1.070      0.289      -1.496       0.455\n",
       "x8            -0.0160      0.045     -0.357      0.723      -0.106       0.074\n",
       "x9            -0.0226      0.032     -0.714      0.478      -0.086       0.041\n",
       "x10            0.0713      0.015      4.897      0.000       0.042       0.101\n",
       "x11           -0.0820      0.038     -2.182      0.034      -0.157      -0.007\n",
       "x12            0.0113      0.030      0.373      0.710      -0.050       0.072\n",
       "x13           -0.0164      0.013     -1.288      0.203      -0.042       0.009\n",
       "x14            0.0009      0.009      0.101      0.920      -0.016       0.018\n",
       "x15           -0.0409      0.021     -1.979      0.053      -0.082       0.001\n",
       "x16            0.1418      0.039      3.681      0.001       0.065       0.219\n",
       "==============================================================================\n",
       "Omnibus:                        6.543   Durbin-Watson:                   1.992\n",
       "Prob(Omnibus):                  0.038   Jarque-Bera (JB):                6.192\n",
       "Skew:                           0.518   Prob(JB):                       0.0452\n",
       "Kurtosis:                       4.025   Cond. No.                     3.15e+05\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 3.15e+05. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_opt_feature = X_opt[: , [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16]]\n",
    "model_opt = sm.OLS(y,X_opt_feature).fit()  #it will tell insignificant vars. SL =5% = 0.5\n",
    "model_opt.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.750</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.713</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   20.02</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 22 May 2019</td> <th>  Prob (F-statistic):</th> <td>5.29e-15</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>23:46:02</td>     <th>  Log-Likelihood:    </th> <td> -51.915</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    70</td>      <th>  AIC:               </th> <td>   123.8</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    60</td>      <th>  BIC:               </th> <td>   146.3</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     9</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>   40.8869</td> <td>   16.045</td> <td>    2.548</td> <td> 0.013</td> <td>    8.791</td> <td>   72.982</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>   -0.6733</td> <td>    0.319</td> <td>   -2.112</td> <td> 0.039</td> <td>   -1.311</td> <td>   -0.036</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>   -0.3461</td> <td>    0.263</td> <td>   -1.317</td> <td> 0.193</td> <td>   -0.872</td> <td>    0.179</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>   -0.4386</td> <td>    0.409</td> <td>   -1.072</td> <td> 0.288</td> <td>   -1.257</td> <td>    0.380</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>   -0.0248</td> <td>    0.021</td> <td>   -1.166</td> <td> 0.248</td> <td>   -0.067</td> <td>    0.018</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td>    0.0686</td> <td>    0.012</td> <td>    5.537</td> <td> 0.000</td> <td>    0.044</td> <td>    0.093</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6</th>    <td>   -0.0843</td> <td>    0.032</td> <td>   -2.621</td> <td> 0.011</td> <td>   -0.149</td> <td>   -0.020</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7</th>    <td>   -0.0142</td> <td>    0.011</td> <td>   -1.268</td> <td> 0.210</td> <td>   -0.037</td> <td>    0.008</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8</th>    <td>   -0.0385</td> <td>    0.015</td> <td>   -2.497</td> <td> 0.015</td> <td>   -0.069</td> <td>   -0.008</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9</th>    <td>    0.1327</td> <td>    0.027</td> <td>    4.879</td> <td> 0.000</td> <td>    0.078</td> <td>    0.187</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 6.351</td> <th>  Durbin-Watson:     </th> <td>   2.040</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.042</td> <th>  Jarque-Bera (JB):  </th> <td>   5.546</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.592</td> <th>  Prob(JB):          </th> <td>  0.0625</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.705</td> <th>  Cond. No.          </th> <td>2.49e+05</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 2.49e+05. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.750\n",
       "Model:                            OLS   Adj. R-squared:                  0.713\n",
       "Method:                 Least Squares   F-statistic:                     20.02\n",
       "Date:                Wed, 22 May 2019   Prob (F-statistic):           5.29e-15\n",
       "Time:                        23:46:02   Log-Likelihood:                -51.915\n",
       "No. Observations:                  70   AIC:                             123.8\n",
       "Df Residuals:                      60   BIC:                             146.3\n",
       "Df Model:                           9                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const         40.8869     16.045      2.548      0.013       8.791      72.982\n",
       "x1            -0.6733      0.319     -2.112      0.039      -1.311      -0.036\n",
       "x2            -0.3461      0.263     -1.317      0.193      -0.872       0.179\n",
       "x3            -0.4386      0.409     -1.072      0.288      -1.257       0.380\n",
       "x4            -0.0248      0.021     -1.166      0.248      -0.067       0.018\n",
       "x5             0.0686      0.012      5.537      0.000       0.044       0.093\n",
       "x6            -0.0843      0.032     -2.621      0.011      -0.149      -0.020\n",
       "x7            -0.0142      0.011     -1.268      0.210      -0.037       0.008\n",
       "x8            -0.0385      0.015     -2.497      0.015      -0.069      -0.008\n",
       "x9             0.1327      0.027      4.879      0.000       0.078       0.187\n",
       "==============================================================================\n",
       "Omnibus:                        6.351   Durbin-Watson:                   2.040\n",
       "Prob(Omnibus):                  0.042   Jarque-Bera (JB):                5.546\n",
       "Skew:                           0.592   Prob(JB):                       0.0625\n",
       "Kurtosis:                       3.705   Cond. No.                     2.49e+05\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 2.49e+05. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_opt_feature = X_opt[: , [0,2,6,7,9,10,11,13,15,16]]\n",
    "model_opt = sm.OLS(y,X_opt_feature).fit()  #it will tell insignificant vars. SL =5% = 0.5\n",
    "model_opt.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_opt_feature, y, test_size=0.10, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.        , -0.65283892, -0.30879908, -0.45358875, -0.01787934,\n",
       "        0.07504849, -0.09855445, -0.01228118, -0.03800442,  0.12489965])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "bias = model.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib64/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['clear', 'cloudy', 'haze', 'rainy'], dtype=object)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode_x.inverse_transform([0,1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.83761069,  1.05135942,  2.19782405,  1.43047948,  1.3484507 ,\n",
       "       -0.36180322,  0.44773547])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 1, 3, 2, 3, 0, 0])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRED = []\n",
    "PRED.append(bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter direction of wind : NE\n"
     ]
    }
   ],
   "source": [
    "win_dir = input(\"Enter direction of wind : \")\n",
    "if win_dir == 'NE':\n",
    "    PRED.append(1)\n",
    "    PRED.append(0)\n",
    "    PRED.append(0)\n",
    "elif win_dir == 'SW':\n",
    "    PRED.append(0)\n",
    "    PRED.append(1)\n",
    "    PRED.append(0)\n",
    "elif win_dir == 'W':\n",
    "    PRED.append(0)\n",
    "    PRED.append(0)\n",
    "    PRED.append(1)\n",
    "else:\n",
    "    PRED.append(0)\n",
    "    PRED.append(0)\n",
    "    PRED.append(0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter Maximum Temperature : 35\n"
     ]
    }
   ],
   "source": [
    "temp = float(input(\"Enter Maximum Temperature : \"))\n",
    "PRED.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter Rainfall : 4.2\n"
     ]
    }
   ],
   "source": [
    "rain = float(input(\"Enter Rainfall : \"))\n",
    "PRED.append(rain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter Evaporation : 1.7\n"
     ]
    }
   ],
   "source": [
    "evap = float(input(\"Enter Evaporation : \"))\n",
    "PRED.append(evap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter Wind Speed : 15\n"
     ]
    }
   ],
   "source": [
    "win_speed = float(input(\"Enter Wind Speed : \"))\n",
    "PRED.append(win_speed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter Pressure : 1010\n"
     ]
    }
   ],
   "source": [
    "pressure = float(input(\"Enter Pressure : \"))\n",
    "PRED.append(pressure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter Cloud : 7\n"
     ]
    }
   ],
   "source": [
    "cloud = float(input(\"Enter Cloud : \"))\n",
    "PRED.append(cloud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRED = np.asarray(PRED,dtype=\"float\")\n",
    "PRED = PRED.reshape(1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_p = model.predict(PRED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.37968088])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "if y_p >= 2.7 :\n",
    "    y_out = 'rainy. You should not go out.'\n",
    "elif y_p >= 1.7 and y_p < 2.7:\n",
    "    y_out = 'haze. You should carry an umbrella with you.'\n",
    "elif y_p >= 0.7 and y_p < 1.7:\n",
    "    y_out = 'cloudy. You may carry an umbrella.'\n",
    "elif y_p >= -1:\n",
    "    y_out = 'clear. Have a nice day.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The weather is cloudy. You may carry an umbrella.\n"
     ]
    }
   ],
   "source": [
    "print(f\"The weather is {y_out}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
